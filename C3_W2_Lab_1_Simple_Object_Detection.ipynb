{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.4"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/jfauv/Advanced-CV-TF-Coursera/blob/master/C3_W2_Lab_1_Simple_Object_Detection.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mmANPR2jhCR6"
      },
      "source": [
        "# Simple Object Detection in Tensorflow\n",
        "\n",
        "This lab will walk you through how to use object detection models available in [Tensorflow Hub](https://www.tensorflow.org/hub). In the following sections, you will:\n",
        "\n",
        "* explore the Tensorflow Hub for object detection models\n",
        "* load the models in your workspace\n",
        "* preprocess an image for inference\n",
        "* run inference on the models and inspect the output\n",
        "\n",
        "Let's get started!"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8DkMLuGDhCR6"
      },
      "source": [
        "## Imports"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OEoRKdmByrb0"
      },
      "source": [
        "import tensorflow as tf\n",
        "import tensorflow_hub as hub\n",
        "from PIL import Image\n",
        "from PIL import ImageOps\n",
        "import tempfile\n",
        "from six.moves.urllib.request import urlopen\n",
        "from six import BytesIO"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nb8MBgTOhCR6"
      },
      "source": [
        "### Download the model from Tensorflow Hub\n",
        "\n",
        "Tensorflow Hub is a repository of trained machine learning models which you can reuse in your own projects.\n",
        "- You can see the domains covered [here](https://tfhub.dev/) and its subcategories.\n",
        "- For this lab, you will want to look at the [image object detection subcategory](https://tfhub.dev/s?module-type=image-object-detection).\n",
        "- You can select a model to see more information about it and copy the URL so you can download it to your workspace.\n",
        "- We selected a [inception resnet version 2](https://tfhub.dev/google/faster_rcnn/openimages_v4/inception_resnet_v2/1)\n",
        "- You can also modify this following cell to choose the other model that we selected, [ssd mobilenet version 2](https://tfhub.dev/tensorflow/ssd_mobilenet_v2/2)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "C9pCzz4uy20U"
      },
      "source": [
        "# you can switch the commented lines here to pick the other model\n",
        "\n",
        "# inception resnet version 2\n",
        "#module_handle = \"https://tfhub.dev/google/faster_rcnn/openimages_v4/inception_resnet_v2/1\"\n",
        "\n",
        "# You can choose ssd mobilenet version 2 instead and compare the results\n",
        "module_handle = \"https://tfhub.dev/google/openimages_v4/ssd/mobilenet_v2/1\""
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "W3trj5FbhCR6"
      },
      "source": [
        "#### Load the model\n",
        "\n",
        "Next, you'll load the model specified by the `module_handle`.\n",
        "- This will take a few minutes to load the model."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model = hub.load(module_handle)"
      ],
      "metadata": {
        "id": "PMECnhiwCjrP"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1Ey0FpHGhCR6"
      },
      "source": [
        "#### Choose the default signature\n",
        "\n",
        "Some models in the Tensorflow hub can be used for different tasks. So each model's documentation should show what *signature* to use when running the model.\n",
        "- If you want to see if a model has more than one signature then you can do something like `print(hub.load(module_handle).signatures.keys())`. In your case, the models you will be using only have the `default` signature so you don't have to worry about other types."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "hub.load(module_handle).signatures.keys()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "51tA4UbCCc6O",
        "outputId": "a30bf6b3-8b1e-49b3-b932-fce2a99fc5d1"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "KeysView(_SignatureMap({'default': <ConcreteFunction pruned(images) at 0x7E5DBF352260>}))"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nfc9ax9hhCR6"
      },
      "source": [
        "Please choose the 'default' signature for your object detector.\n",
        "- For object detection models, its 'default' signature will accept a batch of image tensors and output a dictionary describing the objects detected, which is what you'll want here."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "detector = model.signatures[\"default\"]"
      ],
      "metadata": {
        "id": "WWzKhmhFDDxb"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Wvb-3r3thCR7"
      },
      "source": [
        "### download_and_resize_image\n",
        "\n",
        "This function downloads an image specified by a given \"url\", pre-processes it, and then saves it to disk."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def download_and_resize_image(url, new_width=256, new_height=256):\n",
        "  \"\"\"\n",
        "  Fetches an image online, resizes it and saves it locally.\n",
        "\n",
        "  Args:\n",
        "    url (string) -- link to the image\n",
        "    new_width (int) -- size iin pixels used for resizing the width of the image\n",
        "    new_height (int) -- size in pixels used for resizing the length of the image\n",
        "\n",
        "  Returns:\n",
        "    (string) -- path to saved image\n",
        "  \"\"\"\n",
        "\n",
        "  # create a temporary file ending with \".jpg\"\n",
        "  _, filename = tempfile.mkstemp(suffix=\".jpg\")\n",
        "\n",
        "  # opens the given URL\n",
        "  response = urlopen(url)\n",
        "\n",
        "  # reads the image fetched from the URL\n",
        "  image_data = response.read()\n",
        "\n",
        "  # puts the image data in memory buffer\n",
        "  image_data = BytesIO(image_data)\n",
        "\n",
        "  # opens the image\n",
        "  pil_image = Image.open(image_data)\n",
        "\n",
        "  # resizes the image. will crop if aspect ratio is different.\n",
        "  pil_image = ImageOps.fit(pil_image, (new_width, new_height), Image.ANTIALIAS)\n",
        "\n",
        "  # converts to the RGB colorspace\n",
        "  pil_image_rgb = pil_image.convert(\"RGB\")\n",
        "\n",
        "  # saves the image to the temporary file created earlier\n",
        "  pil_image_rgb.save(filename, format=\"JPEG\", quality=90)\n",
        "\n",
        "  print(\"Image downloaded to %s.\" % filename)\n",
        "\n",
        "  return filename"
      ],
      "metadata": {
        "id": "0MvKt9B5DMqb"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "r7qodEJHhCR7"
      },
      "source": [
        "### Download and preprocess an image\n",
        "\n",
        "Now, using `download_and_resize_image` you can get a sample image online and save it locally.\n",
        "- We've provided a URL for you, but feel free to choose another image to run through the object detector.\n",
        "- You can use the original width and height of the image but feel free to modify it and see what results you get."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# You can choose a different URL that points to an image of your choice\n",
        "image_url = \"https://upload.wikimedia.org/wikipedia/commons/f/fb/20130807_dublin014.JPG\"\n",
        "\n",
        "# download the image and use the original height and width\n",
        "downloaded_image_path = download_and_resize_image(image_url, 3872, 2592)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BMmI6MCHGhi2",
        "outputId": "068a7f76-9ab9-49cc-c715-ccf7869fd751"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Image downloaded to /tmp/tmp928pdo7n.jpg.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-6-3accc599519f>:30: DeprecationWarning: ANTIALIAS is deprecated and will be removed in Pillow 10 (2023-07-01). Use LANCZOS or Resampling.LANCZOS instead.\n",
            "  pil_image = ImageOps.fit(pil_image, (new_width, new_height), Image.ANTIALIAS)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IVNXUKMIhCR7"
      },
      "source": [
        "### run_detector\n",
        "\n",
        "This function will take in the object detection model `detector` and the path to a sample image, then use this model to detect objects and display its predicted class categories and detection boxes.\n",
        "- run_detector uses `load_image` to convert the image into a tensor."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def load_img(path):\n",
        "  \"\"\"\n",
        "  Loads a JPEG image and converts it to a tensor.\n",
        "\n",
        "  Args:\n",
        "    path (string) -- path to a locally saved JPEG image\n",
        "\n",
        "  Returns:\n",
        "    (tensor) -- an image tensor\n",
        "  \"\"\"\n",
        "\n",
        "  # read the file\n",
        "  img = tf.io.read_file(path)\n",
        "\n",
        "  # convert to a tensor\n",
        "  img = tf.image.decode_jpeg(img, channels=3)\n",
        "\n",
        "  return img\n",
        "\n",
        "def run_detector(detector, path):\n",
        "  \"\"\"\n",
        "  Runs inference on a local files using an object detection model.\n",
        "\n",
        "  Args:\n",
        "    detector (model) -- an object detection model loaded from TF hub\n",
        "    path (string) -- path to an image saved locally\n",
        "  \"\"\"\n",
        "\n",
        "  # load an image tensor from a local file path\n",
        "  img = load_img(path)\n",
        "\n",
        "  # add a batch dimension in front of the tensor\n",
        "  converted_img = tf.image.convert_image_dtype(img, tf.float32)[tf.newaxis, ...]\n",
        "\n",
        "  # run inference using the model\n",
        "  result = detector(converted_img)\n",
        "\n",
        "  # save the results in a dictionary\n",
        "  result = {key: value.numpy() for key, value in result.items()}\n",
        "\n",
        "  # print results\n",
        "  print(\"Found %d objects.\" % len(result[\"detection_scores\"]))\n",
        "\n",
        "  print(result[\"detection_scores\"])\n",
        "  print(result[\"detection_class_entities\"])\n",
        "  print(result[\"detection_boxes\"])"
      ],
      "metadata": {
        "id": "DuEnOLhYHX4s"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DSEeJSkxhCR7"
      },
      "source": [
        "### Run inference on the image\n",
        "\n",
        "You can run your detector by calling the `run_detector` function. This will print the number of objects found followed by three lists:\n",
        "\n",
        "* The detection scores of each object found (i.e. how confident the model is),\n",
        "* The classes of each object found,\n",
        "* The bounding boxes of each object\n",
        "\n",
        "You will see how to overlay this information on the original image in the next sections and in this week's assignment!"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# runs the object detection model and prints information about the objects found\n",
        "run_detector(detector, downloaded_image_path)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bILURmIyI-MH",
        "outputId": "92fafc8f-fe02-40f7-b7af-a41ff1ba658b"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 100 objects.\n",
            "[0.436388   0.3488732  0.24501613 0.23388161 0.22632208 0.2156073\n",
            " 0.20603243 0.20521504 0.20307639 0.19840115 0.18880866 0.18106377\n",
            " 0.18082245 0.17998277 0.17989479 0.17721444 0.17477798 0.17303872\n",
            " 0.17053543 0.16971526 0.16919276 0.16825813 0.1642754  0.16199107\n",
            " 0.16110268 0.16060077 0.16035771 0.1596943  0.1577436  0.15739347\n",
            " 0.15714587 0.15653816 0.15279417 0.1499805  0.14963487 0.14810573\n",
            " 0.14709249 0.1470065  0.14588015 0.1457028  0.14534342 0.14526632\n",
            " 0.14403893 0.14400737 0.14383514 0.14284107 0.14267781 0.14242578\n",
            " 0.14031248 0.13963945 0.13949175 0.13740636 0.13706668 0.13699545\n",
            " 0.13636456 0.13557202 0.13488966 0.13072284 0.1301368  0.12861584\n",
            " 0.12749374 0.12689273 0.1265813  0.12564696 0.12514336 0.1230045\n",
            " 0.12287524 0.12273064 0.12224491 0.1222197  0.12181569 0.12164262\n",
            " 0.1208571  0.12058606 0.11993121 0.11953843 0.11838248 0.11800458\n",
            " 0.11747291 0.11726157 0.11694559 0.11667921 0.11636377 0.11611395\n",
            " 0.11582799 0.11541581 0.11513458 0.11508507 0.11461011 0.11417458\n",
            " 0.11414687 0.1130922  0.11307351 0.11273248 0.11261337 0.1124935\n",
            " 0.11227394 0.11153267 0.11114075 0.11103164]\n",
            "[b'Person' b'Footwear' b'Footwear' b'Building' b'Person' b'Footwear'\n",
            " b'Window' b'Building' b'Person' b'Window' b'Window' b'Window' b'Window'\n",
            " b'Window' b'Footwear' b'Person' b'Window' b'Window' b'Window' b'Window'\n",
            " b'Window' b'Window' b'Window' b'Window' b'Window' b'Window' b'Window'\n",
            " b'Window' b'Window' b'Window' b'Person' b'Window' b'Window' b'Window'\n",
            " b'Person' b'Window' b'Window' b'Window' b'Person' b'Window' b'Building'\n",
            " b'Window' b'Building' b'Window' b'Window' b'Person' b'Person' b'Window'\n",
            " b'Person' b'Window' b'Window' b'Window' b'Window' b'Window' b'Window'\n",
            " b'Window' b'Building' b'Person' b'Window' b'Window' b'Building' b'Window'\n",
            " b'Window' b'Window' b'Window' b'Person' b'Window' b'Window' b'Window'\n",
            " b'Window' b'Building' b'Window' b'Window' b'Window' b'Window' b'Building'\n",
            " b'Window' b'Bicycle' b'Window' b'Building' b'Window' b'Window' b'Window'\n",
            " b'Building' b'Window' b'Man' b'Window' b'Person' b'Window' b'Window'\n",
            " b'Window' b'Building' b'Building' b'Building' b'Window' b'Window'\n",
            " b'Traffic light' b'Window' b'Building' b'Building']\n",
            "[[0.51296306 0.9169887  0.8215138  0.9923356 ]\n",
            " [0.8011385  0.9544148  0.8313205  0.9813046 ]\n",
            " [0.7976416  0.9425527  0.82654244 0.9652647 ]\n",
            " [0.         0.         0.6767998  0.38964126]\n",
            " [0.49197546 0.4161907  0.6890061  0.46767095]\n",
            " [0.77756685 0.9471243  0.8025134  0.96229535]\n",
            " [0.01544128 0.3414744  0.14134577 0.36409402]\n",
            " [0.26337305 0.56487083 0.5526066  0.6751772 ]\n",
            " [0.49657172 0.3760996  0.66730565 0.4211774 ]\n",
            " [0.00222111 0.1329546  0.21256962 0.17372945]\n",
            " [0.         0.28084058 0.08188882 0.31301355]\n",
            " [0.04951972 0.7527908  0.12832183 0.8040745 ]\n",
            " [0.07496383 0.39330333 0.19655451 0.4137175 ]\n",
            " [0.05147726 0.8764222  0.2543448  0.9055863 ]\n",
            " [0.7531605  0.95593363 0.80580854 0.98118323]\n",
            " [0.5201693  0.51619464 0.5977562  0.5369471 ]\n",
            " [0.         0.9707533  0.16356838 0.99980617]\n",
            " [0.00771925 0.10757063 0.2333031  0.18325217]\n",
            " [0.15521643 0.45476025 0.22095194 0.48177212]\n",
            " [0.17821185 0.74791557 0.32171035 0.7765632 ]\n",
            " [0.07284555 0.36293277 0.17593712 0.37904742]\n",
            " [0.13706172 0.27886432 0.27287734 0.302611  ]\n",
            " [0.01314989 0.8112952  0.13430355 0.8393727 ]\n",
            " [0.17654586 0.3309639  0.3327744  0.35620314]\n",
            " [0.16296831 0.745183   0.2436485  0.77434254]\n",
            " [0.15703283 0.2884951  0.29813373 0.31091014]\n",
            " [0.         0.14719884 0.22948857 0.19050382]\n",
            " [0.17460692 0.8141822  0.3544792  0.8380949 ]\n",
            " [0.008637   0.30223727 0.11006004 0.32785046]\n",
            " [0.17208363 0.7089806  0.22653724 0.7289503 ]\n",
            " [0.52992827 0.5448189  0.5878838  0.56480455]\n",
            " [0.09832712 0.7547094  0.1544043  0.7824804 ]\n",
            " [0.12916803 0.251205   0.2557168  0.27308634]\n",
            " [0.14564978 0.328324   0.26691723 0.35278168]\n",
            " [0.5539824  0.60355    0.6423174  0.6361025 ]\n",
            " [0.         0.32805762 0.08483668 0.3514568 ]\n",
            " [0.19605584 0.7069154  0.31686628 0.7272428 ]\n",
            " [0.00238045 0.         0.13669428 0.02396841]\n",
            " [0.5325351  0.60544455 0.58627033 0.6353123 ]\n",
            " [0.08601608 0.8823382  0.24944276 0.909671  ]\n",
            " [0.05278113 0.4053586  0.58979845 0.5663431 ]\n",
            " [0.12103823 0.40967044 0.21891484 0.42461333]\n",
            " [0.23847538 0.5916037  0.5405759  0.7040872 ]\n",
            " [0.16119839 0.4885566  0.22007774 0.5064851 ]\n",
            " [0.24185988 0.39245194 0.36473492 0.4125768 ]\n",
            " [0.53164715 0.7613151  0.58643574 0.77987957]\n",
            " [0.48776042 0.21942261 0.6916264  0.2648275 ]\n",
            " [0.22059204 0.34889883 0.33952022 0.36707717]\n",
            " [0.5065807  0.3441742  0.6281706  0.36818302]\n",
            " [0.02564329 0.84697056 0.3254719  0.9254352 ]\n",
            " [0.04520376 0.8878563  0.24210776 0.92814404]\n",
            " [0.15393032 0.81957203 0.26990175 0.84217936]\n",
            " [0.02017135 0.38974863 0.17767501 0.41705734]\n",
            " [0.21203814 0.4215094  0.27755767 0.4526726 ]\n",
            " [0.07018535 0.8154426  0.16685158 0.83806545]\n",
            " [0.01936691 0.86725485 0.22104636 0.8977325 ]\n",
            " [0.00867432 0.76449347 0.61508465 0.9921758 ]\n",
            " [0.5372311  0.71977836 0.5842469  0.7356283 ]\n",
            " [0.23365231 0.7535617  0.33913562 0.7757043 ]\n",
            " [0.20541199 0.98377776 0.27542722 0.9995322 ]\n",
            " [0.         0.23558193 0.6205113  0.4320624 ]\n",
            " [0.20972945 0.4129528  0.29312193 0.4306769 ]\n",
            " [0.29584783 0.45426664 0.38301003 0.47706768]\n",
            " [0.08886994 0.24340223 0.21355638 0.26685423]\n",
            " [0.00266442 0.13013723 0.24373913 0.20930693]\n",
            " [0.49790668 0.8114655  0.60154724 0.833091  ]\n",
            " [0.22447833 0.5084963  0.27840063 0.52387404]\n",
            " [0.09477142 0.27367848 0.20409068 0.2990538 ]\n",
            " [0.         0.24216384 0.04003197 0.26647824]\n",
            " [0.00131817 0.21702981 0.20465015 0.24757135]\n",
            " [0.36242768 0.3913824  0.5368158  0.59546876]\n",
            " [0.24898234 0.7089798  0.3370901  0.7263307 ]\n",
            " [0.27049646 0.44675985 0.36061993 0.46755704]\n",
            " [0.08908589 0.97358906 0.17066886 0.9992006 ]\n",
            " [0.32456687 0.90258574 0.38428375 0.92827296]\n",
            " [0.         0.13965376 0.64226425 0.40302408]\n",
            " [0.11489725 0.44422302 0.18230572 0.4711477 ]\n",
            " [0.61010766 0.37222096 0.7104683  0.42082796]\n",
            " [0.00259168 0.8178466  0.07235143 0.84149534]\n",
            " [0.         0.00355099 0.7305368  0.25568444]\n",
            " [0.11902156 0.14217632 0.22330385 0.17359479]\n",
            " [0.11985157 0.1467546  0.23253836 0.18491125]\n",
            " [0.00265061 0.15475535 0.07459648 0.19224206]\n",
            " [0.31888908 0.49988347 0.5404523  0.7114572 ]\n",
            " [0.00302822 0.8939262  0.2235901  0.952889  ]\n",
            " [0.51296306 0.9169887  0.8215138  0.9923356 ]\n",
            " [0.38299924 0.8957405  0.53394705 0.9323286 ]\n",
            " [0.5011413  0.3542833  0.70662475 0.44481012]\n",
            " [0.15770383 0.25268748 0.29831368 0.27323988]\n",
            " [0.00754378 0.38705796 0.07390296 0.42119634]\n",
            " [0.27489352 0.40563717 0.39017022 0.42241558]\n",
            " [0.22354183 0.4315069  0.5767255  0.56812227]\n",
            " [0.         0.2239126  0.57991076 0.7049881 ]\n",
            " [0.05578676 0.37843615 0.57680964 0.6573219 ]\n",
            " [0.11885737 0.71988225 0.15101548 0.73561287]\n",
            " [0.3388048  0.7614373  0.3819026  0.7814666 ]\n",
            " [0.41516283 0.5049735  0.48099336 0.526491  ]\n",
            " [0.28023112 0.93447214 0.3218637  0.95133907]\n",
            " [0.34694326 0.59269834 0.45970774 0.6258172 ]\n",
            " [0.         0.4923486  0.59991497 0.9413964 ]]\n"
          ]
        }
      ]
    }
  ]
}